{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с [логами рекомендательной системы фильмов](https://grouplens.org/datasets/movielens/). Основой данных будут две таблицы. Первая — это данные о выставленных оценках фильмов ([ratings.csv](https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/data/ratings.csv)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings = pd.read_csv('../data/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- userId — идентификатор пользователя, который поставил фильму оценку\n",
    "- movieId — идентификатор фильма\n",
    "- rating — выставленная оценка\n",
    "- timestamp — время (в формате unix time), когда была выставлена оценка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая таблица — расшифровка идентификаторов фильмов ([movies.csv](https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/data/movies.csv)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- movieId — идентификатор фильма\n",
    "- title — название фильма\n",
    "- genres — список жанров, к которым относится фильм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наглядный [пример](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) различных режимов склейки таблиц по строкам или столбцам (метод concat). Пригодится, чтобы быстро вспомнить, как изменять типы объединения таблиц.\n",
    "- Документация [метода merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) — пригодится, если забылись названия основных параметров (по каким столбцам объединяем таблицы и каким способом).\n",
    "- [Объяснение](http://www.skillz.ru/dev/php/article-Obyasnenie_SQL_obedinenii_JOIN_INNER_OUTER.html) типов объединений таблиц — если возникнут трудности с выбором типа объединения (в pandas.merge параметр how)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У датафреймов ratings и movies есть общий столбец movieId. Значит, мы можем объединить эти датафреймы в одну таблицу. Используем метод merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = ratings.merge(movies, on='movieId', how='left')\n",
    "joined.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схематично метод merge можно описать так: \n",
    "\n",
    "```Python\n",
    "joined = left_df.merge(right_df, on='', how='').\n",
    "```\n",
    "\n",
    "Давайте разберем подробнее параметры метода: \n",
    "\n",
    "- left_df / right_df — датафреймы, которые мы объединяем. К \"правому\" датафрейму присоединяем \"левый\" (в нашем примере \"левый\" датафрейм — ratings, \"правый\" — movies). \n",
    "- how — параметр объединения записей. Он может иметь четыре значения: left, right, inner и outer. При значении left берем все записи (movieId) из \"левого\" датафрейма (ratings) и ищем их соответствия в \"правом\" (movies). В итоговом датафрейме останутся только те значения, которым были найдены соответствия, то есть только значения из ratings. Аналогично при параметре right остаются только значения из \"правого\" датафрейма. Если совпадений между таблицами нет, то ставим нулевое значение. Значение inner оставляет только те записи (movieId), которые есть в обоих датафреймах, outer объединяет все варианты movieId в обоих датафреймах. \n",
    "- on определяет, по какому столбцу происходит объединение. Для объединения по нескольким столбцам используйте on = ['col1', 'col2'] или left_on и right_on.\n",
    "\n",
    "После объединения датафреймов лучше проверять, что не возникло дубликатов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас убедимся в том, что число строк объединенного датафрейма совпадает с исходным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratings) == len(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем значение True — значит, число строк совпадает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединение датафреймов с помощью метода merge имеет особенности, аналогичные SQL JOIN. Если точнее, есть ситуации, которые приводят к дублированию строк в конечном результате. Разберем эти ситуации более подробно на примере небольших таблиц: [ratings_example.txt](https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/data/ratings_example.txt) и [movies_example.txt](https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/data/movies_example.txt).\n",
    "\n",
    "В этих таблицах всего несколько строк, что позволит наглядно проверить, где дублируются результаты. Скачайте эти файлы себе и импортируйте в датафреймы ratings и movies. Обратите внимание, что разделителем столбцов в этих файлах является табуляция (\\t):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings = pd.read_csv('../data/ratings_example.txt', sep = '\\t')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/movies_example.txt', sep = '\\t')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дубликаты строк**\n",
    "\n",
    "Итак, в датафрейме movies есть две строки с одним movieId. То есть теперь для таблицы ratings нет однозначного соответствия, с какой строкой она может объединиться с таблицей movies. В итоге строка с movieId = 31 будет дублирована:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.merge(movies, how='left', on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удаляем дубликаты**\n",
    "\n",
    "Если вы хотите избежать подобной ситуации, необходимо удалить дубликаты из таблицы movies. Для этого подходит метод drop_duplicates. В параметре subset указываем один или несколько столбцов, по комбинации которых хотим удалить дубликаты.\n",
    "\n",
    "С помощью параметра keep указываем, какой из встречающихся дубликатов оставить (например, первый или последний). Параметр inplace указывает, что изменения нужно сохранить в датафрейме, к которому применяется метод (в нашем случае — в датафрейме movies):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.drop_duplicates(subset='movieId', keep='first', inplace=True)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь объединение таблиц будет корректным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.merge(movies, how='left', on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "В этой серии заданий мы разберемся с данными новых поступлений интернет-магазина. В словаре items_dict (который мы переведем в датафрейм) содержится информация о наличии товара на складе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dict = {\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 100132, 312394], \n",
    "    'vendor': ['Samsung', 'LG', 'Apple', 'Apple', 'LG', 'Apple', 'Samsung', 'Samsung', 'LG', 'ZTE'],\n",
    "    'stock_count': [54, 33, 122, 18, 102, 43, 77, 143, 60, 19]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А в словаре purchase_log — данные о покупках товаров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_log = {\n",
    "    'purchase_id': [101, 101, 101, 112, 121, 145, 145, 145, 145, 221],\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 103845, 100132], \n",
    "    'price': [13900, 5330, 38200, 49990, 9890, 33000, 67500, 34500, 89900, 11400]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- item_id — идентификатор модели (по этому столбцу будем объединять датафреймы)\n",
    "- vendor — производитель модели\n",
    "- stock_count — имеющееся на складе количество данных моделей (в штуках)\n",
    "- purchase_id — идентификатор покупки\n",
    "- price — стоимость модели в покупке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем сначала эти словари в датафреймы для удобства работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.DataFrame(items_dict)\n",
    "purchase_df = pd.DataFrame(purchase_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Объедините получившиеся датафреймы по столбцу item_id с типом outer.\n",
    "\n",
    "Определите, модель с каким item_id есть в статистике продаж purchase_df, но не учтена на складе (подсказка: подумайте, какой датафрейм должен быть \"левым\", а какой \"правым\", чтобы получить необходимые данные). Введите ответ в виде целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Решите обратную задачу: модель с каким item_id есть на складе, но не имела ни одной продажи? Введите ответ в виде целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "\n",
    "Сформируйте датафрейм merged, в котором в результате объединения purchase_df и items_df останутся модели, которые учтены на складе и имели продажи. Сколько всего таких моделей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "\n",
    "Посчитайте объем выручки для каждой модели, которую можно получить, распродав все остатки на складе. Модель с каким item_id имеет максимальное значение выручки после распродажи остатков? Ответ дайте в виде целого числа.\n",
    "\n",
    "Примечание: перемножение столбцов датафрейма можно производить разными способами, но самый простой - перемножение \"в лоб\" вида df['col1'] = df['col2'] * df['col3']. Для присоединения новых данных к датафрейму тоже можно использовать различные методы, включая функцию .append(), которая позволяет присоединять к датафрейму другой датафрейм, серии или словари."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5\n",
    "\n",
    "Посчитайте итоговую выручку из прошлого задания по всем моделям. Ответ дайте в виде целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
